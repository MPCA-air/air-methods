# Get data

```{r, echo=F}

knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)

dt_options <- list(scrollX = T, autoWidth = T, searching = F, ordering = F, lengthChange = F, paginate = F, info = F)
```

<br>

![](images/cover1.jpg){align="right" style="margin-top: -4px; margin-left: 20px; width: 36%;"}

This section describes how to download air monitoring and modeling data. 


__Air monitoring data__

- Final data <br>
    - \@ref(AQS) EPA AQS Database 
    - \@ref(rqamd) EPA AQS Datamart (RQAMD Package)
    - \@ref(lims) MPCA LIMS data via Tableau
    - \@ref(wair) MPCA WAIR Database
- Preliminary data 
    - \@ref(aqi-now)  AirNow: Current AQI observations
    - \@ref(AirVision) AirVision: Continuous data
 - Air Monitoring Site Information 
    - \@ref(wairsites) WAIR Site Table
    - \@ref(monitors) AirNow: Active AQI monitors 
    - \@ref(EPAsites) EPA Google Earth Site Explorer
    


__Summarized air monitoring results__

- External Data Explorers
    - \@ref(toxics) Air Toxics Data Explorer
    - \@ref(criteria) Criteria Pollutant Data Explorer
    - \@ref(AQI) Air Quality Index Summary Reports
    - \@ref(PAHs) Air Monitoring for PAHs 
- Internal Data Explorers 
    - \@ref(tableau) MPCA Tableau Server

__Health benchmarks and air quality standards__

- Air toxics
    - \@ref(IHBs) Inhalation health benchmarks
- Criteria pollutants
    - \@ref(NAAQS) Air Quality Standards (NAAQs and MAAQS)

__Air modeling__

- Modeling results
    - \@ref(nata) NATA
    - \@ref(mnrisks) MNRISKS
    - \@ref(downscale) Downscaler for Ozone and PM2.5
    - \@ref(cmaq) CMAQ 


__Context__

- Emissions
    - \@ref(mn-ei) MN Emissions Inventory
    - \@ref(nei) EPA's NEI
    - \@ref(fac-coords) Facility locations

- Meteorology and Climate
    - \@ref(wx-obs) Weather observations
    - \@ref(hysplit) HYSPLIT wind trajectories
    
- Geography and Census data
    - \@ref(landuse) Land use maps
    - \@ref(census) U.S. Census boundaries
    - \@ref(acs) Demographics from American Community Survey (ACS) 

<br>


## Air monitoring 

### Retrieving data from AQS {#AQS}
The Air Quality System (AQS) contains ambient air pollution data collected by EPA, state, local, and tribal air pollution control agencies from over thousands of monitors. AQS also contains meteorological data, descriptive information about each monitoring station (including its geographic location and its operator), and data quality assurance/quality control information.

Registered users can access the AQS database via a web application at https://www.epa.gov/aqs. Raw data extracts can be run using the AMP501 report. The AMP501 provides data in the pipe delimited RD transaction format. 


### Retrieving data from AQS DataMart {#rqamd}
The AQS Data Mart provides a convenient API to access air quality data stored in the EPA's AQS database, [AQS Data Mart] (https://aqs.epa.gov/aqsweb/documents/data_mart_welcome.html)

Note: The AQS Data Mart requires a user name and password. The username and password is not the same as your AQS User Account. To request a Data Mart account, follow the instructions on the Data Mart page. 

The `RQAMD` package allows users to query the AQS Data Mart in R, see [RQAMD](https://github.com/ebailey78/raqdm) on Github.

Warning: Data from AQS Data Mart does not include null results.

<br> __Sample `R` script__ 

Click the button below to view a step by step example.

<div class="toggle">
<button class = "btn_code">Show __R__ code</button>

```{r, eval=FALSE }

##install raqdm package
library(devtools)
devtools::install_github("ebailey78/raqdm")
library(raqdm)

##set Data Mart username and password.

setAQDMuser("User Name","PW",save=TRUE) #Note save=TRUE creates a file that stores username and password locally, you will not need to run setuser info each time you load raqdm. 

setAQDMdefaults(pc="CRITERIA", state="27", save=TRUE) #Set defaults that are locally stored for queries. This eliminates need to define the data type and state code. 


## Single parameter query

x <- getAQDMdata(state="27",pc="CRITERIA",param="42602",format="AQCSV",bdate="20140101",edate="20141231",synchronous = FALSE) # Queries Data Mart DataBase

aqcsv <- getAQDMrequest(x) # Wait for email confirming file is ready. 


## Multiple parameter loops


params <- c("45201", "42602", "44201") #Create a vector with the parameters you are interested in

# Use lapply to loop through the params vector, requesting each one from AQDM. A list of requests will be returned to the x variable
x <- lapply(params, function(p) {
  return(getAQDMdata(param=p))
})

# Now loop through the requests to retrieve the data
y <- lapply(x, function(r) {
  return(getAQDMrequest(r))
})

# Use do.call and rbind to combine them into one data.frame
d <- do.call(rbind, y)

```
</div>

<br>


### Current AQI observations {#aqi-now}

Real-time air data for the entire United States is at your finger tips. _EPA's AirNow_ maintains a publicly accessible folder of current air monitoring data at https://files.airnowtech.org/. Data retrieved from AirNow is preliminary and may change following quality assurance. 

<br> __Sample `R` script__  
  
Use the following R code to grab the most recent AQI results for the entire country.



<div class="toggle">
<button class = "btn_code">Show __R__ code</button>


```{r}
library(dplyr)
library(readr)

# Connect to AirNow data site
#https://files.airnowtech.org/

airnow_link <- paste0("https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/today/",
                      "HourlyData_",
                      format(Sys.time() - 60*75, "%Y%m%d%H", tz = "GMT"),
                      ".dat")
  
aqi_now   <- read_delim(airnow_link, "|", 
                        col_names = F)
                        #col_types = c('cccciccdc'))
 
# Add column names
names(aqi_now) <- c("date", "time", "aqsid", "city", "local_time", "parameter", "units", "concentration", "agency")


# Filter to Ozone and PM2.5 results
aqi_now <- filter(aqi_now, parameter %in% c("OZONE", "PM2.5"))
 
```
</div>

### WAIR Site information table {#wairsites}
The WAIR database includes a copy of the EPA site information table, which includes site names and location information. 


__Sample `R` script__ 

Click the button below to view a step by step example.

<div class="toggle">
<button class = "btn_code">Show __R__ code</button>


```{r, eval=F}
library(RPostgreSQL)
username <- #Add WAIR UserName
pass <- #Add WAIR password

## Load the PostgreSQL driver
drv <- dbDriver("PostgreSQL") 

## Open a connection 
con <- dbConnect(drv, dbname="wair",host='eiger',user=username,password=pass) 

sites <- dbGetQuery(con, 
                    statement = paste(
                      "SELECT *
                      FROM wair.aqs.site  \
                      "
                    )); 

dbDisconnect(con)   ## Closes the connection
dbUnloadDriver(drv) ## Frees all the resources on the driver

```

</div>


### AirNow:Active AQI monitors {#monitors}

A map of MPCA's air monitoring network is available online at [Minnesota air monitoring sites](https://www.pca.state.mn.us/air/minnesota-air-monitoring-sites).

A list of all active AQI monitoring locations around the United States are published to [_AirNow_](https://files.airnowtech.org/?prefix=airnow/today/) in the `monitoring_site_locations.dat` file.


<br> __Sample `R` script__ 

Click the button below to view a step by step example.

<div class="toggle">
<button class = "btn_code">Show __R__ code</button>


```{r }
library(dplyr)
library(readr)

# Connect to AirNow data site
#https://files.airnowtech.org/

airnow_link <- paste0("https://s3-us-west-1.amazonaws.com//files.airnowtech.org/airnow/today/",
                      "monitoring_site_locations.dat")
  
aqi_sites   <- read_delim(airnow_link, "|", col_names = F)
 
# Drop empty columns
aqi_sites <- aqi_sites[ , -c(14:16,22:23)]

# Add column names
names(aqi_sites) <- c("aqsid", 
                      "parameter", 
                      "local_id", 
                      "name", 
                      "status", 
                      "state_region", 
                      "agency", 
                      "epa_region", 
                      "lat", 
                      "long", 
                      "elevation",
                      "local_time",
                      "country",
                      "city",
                      "state_fips",
                      "state",
                      "county_fips",
                      "county")
                    

# Filter to Minnesota sites
aqi_sites  <- filter(aqi_sites, state_fips %in% c(27))
 
```

</div>

<br>


### EPA Google Earth Site Maps {#EPAsites}

The AirData Air Quality Monitors app is a mapping application available on the web and on mobile devices that displays monitor locations and monitor-specific information. It also allows the querying and downloading of data daily and annual summary data.  Static KMZ files are also available to download.

https://www.epa.gov/outdoor-air-quality-data/interactive-map-air-quality-monitors

### Retrieving data from LIMS via Tableau {#lims}

The LIMS database is the primary data warehouse for AQ monitoring activities. The LIMS system is being retired and replaced. To ease data accessibilty during this transition LIMS data are available for download via an internal Tableau workbook at http://tableau.pca.state.mn.us/#/workbooks/3342

<br> __Sample `R` script__ 

The following function reads LIMS data from Tableau. All inputs must be provided. The inputs are:

Sites: Integer vector representing site numbers (no state code, county code, or POC)
Parameter_list: Integer vector representing parameters to extract.
Start_date: Character string of date in YYYY-MM-DD format (or other format recognized by ymd())
End_date: Character string of date in YYYY-MM-DD format (or other format recognized by ymd())
Pollutant_Groups: Character vector of pollutant groups to extract. Air toxics include "metals (TSP)", "VOCs", "carbonyls".

<div class="toggle">
<button class = "btn_code">Show __R__ code</button>


```{r}
read_AT_data_tableau = function(Sites, Parameter_list, Start_date = "2016-01-01", End_date = "2016-03-31", Pollutant_Groups = c("metals (TSP)", "VOCs", "carbonyls")) {
  
  sample_calendar <- function(start         = "2016-01-01", 
                              end           = "2016-12-31", 
                              day_interval  = 6,
                              type          = "air_toxics") {
    
    library(lubridate)
    
    # Convert 'start' and 'end' to class date
    start <- ymd(start)
    end   <- ymd(end)
    
    # Set official start date to selected EPA calendar
    if(type == "air_toxics") {
      epa_start <- ymd("1989-12-24")
    } else {
      epa_start <- start
    }
    
    # Create full table of sampling dates
    calendar <- seq(from = epa_start, 
                    to   = end, 
                    by   = paste(day_interval, "days"))
    
    
    # Subset to user's date range
    calendar <- calendar[calendar >= start & calendar <= end]
    
    return(calendar)
    
  }
  
  # Generate air toxics sampling dates
  
  Dates = sample_calendar(Start_date, End_date)
  
  # Break dates into quarters
  
  Quarters = quarter(Dates, with_year = T)
  
  library(tidyverse)
  
  # Convert fields to Tableau url format
  
  base_url = "http://tableau.pca.state.mn.us/views/exportDailyData/Datawithnullcodes.csv?"
  Sites = paste(paste0(Sites,"-1", collapse = ","), paste0(Sites,"-2", collapse = ","), sep = ",")
  Testnames = Pollutant_Groups %>% url_encode() %>% paste0(collapse = ",")
  Analytes = url_encode(Analytes) %>% gsub("%2c", "%5C%2C",.) %>% paste0(collapse = ",")
  Parameter_list = paste0(Parameter_list, collapse = ",")
  AT_data = NULL
  
  for (i in unique(Quarters) ) {
  
  Dates2 = paste0(Dates[Quarters == i], collapse = ",")
  
  #Construct url for Tableau
  
  url = paste0(base_url,
                "site%20and%20poc=", Sites,
                "&TESTNAME=", Testnames,
                "&ANALYTES_ANALYTE=", Analytes,
                "&PARAMCODE=", Parameter_list,
                "&RUNDATE=", Dates2
  )
  
  # Read data from Tableau server
  
  AT_data = bind_rows(AT_data, read_csv(url, col_types = "ccccicccd") )
  
  }
  
  return(AT_data)
}
```
</div>

### Retrieving continuous data from AirVision {#AirVision}

AirVision is the data acquistion and temporary storage database for continuous air monitoring data. Data collected in AirVision is transfered to LIMs and AQS for final data storage. If you need the most recent monitoring observations and would like to access continuous data before it has been transfered to the final data repository you can run reports from AirVision.

To run reports, the AirVision client must be installed on your computer and you need a user account. Contact the Air Monitoring Supervisor to request credentials. Alternatively, an AirVision administator can create a report task that will generate a data report and send it to a specified location (FTP site or e-mail). 


### Retrieving data from MPCA WAIR database {#wair}

The WAIR database provides a queryable local copy of select air quality data extracted from multiple data sources. This database is managed by Margaret McCourtney.Contact Margaret to request login credentials. 

See [WAIR Data Dictionary](http://rainier.pca.state.mn.us/documentation/DataDictionary/wair/index.html) for available data tables.

Use the following code to query WAIR using the R package `dplyr`.

<div class="toggle">
<button class = "btn_code">Show __R__ code</button>



```{r, eval=FALSE}
################################################################################################
## This script loads the library and driver and connects to WAIR.  A dplyr query extracts 
## data from the database into a format specified by Cassie McMahon for calculating           
## OZONE DESIGN VALUES                                                                        
##                                                                                    
## Note: WAIR does not contain values for SamplingFrequency and MonitorProtocolID 
##
## Note:  dplyr does not have a command to disconnect from the database. Connection will
## terminate upon quitting R.  Please do not keep (many) connections open for long periods of
## time.
################################################################################################

## Load the package
library(dplyr)

## Open a connection to the database WAIR, schema AQS ##
my_wair <- src_postgres(dbname = 'wair', host = "eiger", user = "username", password = "password",
options = "-c search_path=aqs")

## Reference a table, or two if combining, in the database (e.g. aqs.monitor & aqs.obs_value) ##
## Select columns and filter by row ##

#aqs.monitor table in WAIR ##
my_monitor <- tbl(my_wair, "monitor") %>% 
                select(id_mon:poc_code) %>%  
                filter(stateid==27 && parm_code == 44201)

#aqs.obs_value table in WAIR ##
my_obs <- tbl(my_wair, "obs_value") %>% 
            filter(parm_code == 44201 && between(sampldate, "2014-06-01", "2014-06-07")) %>%
              select(id_mon, dur_code, unitid, method_code,
                     sampldate, startime, value, nulldata, qual_code)

## Combine monitor data with observations 
my_mn_o3 <- inner_join(my_monitor, my_obs, type = "inner", by = c("id_mon")) 


## Collect data into a dataframe or table 
my_mn_o3_df <- collect(my_mn_o3) %>% 
                 arrange(stateid, cntyid, siteid, parm_code,  # Arrange combined data in specified order
                         poc_code, dur_code, unitid, method_code, 
                         sampldate, startime, value, nulldata, qual_code)

## 
head(my_mn_o3_df)

```
</div>

<br>


Use the following code to query WAIR using the package `RPostgrSQL`.

<div class="toggle">
<button class = "btn_code">Show __R__ code</button>


```{r, eval = FALSE}
################################################################################################
## This script loads the library and driver and connects to WAIR.  A PostgrSQL query extracts 
## data from the database into a format specified by Cassie McMahon for calculating           
## OZONE DESIGN VALUES                                                                        
##                                                                                    
## Please disconnect from database and unload the driver before proceeding with analysis of 
## the data in your dataframe.
##
## Cassie's headings
## "State.Code", "County.Code", "Site.ID", "Parameter", "POC", "Sample.Duration", "Unit",
## "Method", "Date", "Start.Time", "Sample.Value", "NullDataCode", "SamplingFrequency",
## "MonitorProtocolID", "Qual1"  
##  Note: WAIR does not contain values for SamplingFrequency and MonitorProtocolID 
##
################################################################################################

## call the library
library(RPostgreSQL)

## load the PostgreSQL driver
drv <- dbDriver("PostgreSQL")

## Open a connection 
con <- dbConnect(drv, dbname = "wair", host = 'eiger', user = 'username', password = 'password')

#***************************** all in 1 step ***************************************************


dframe <- dbGetQuery(con, 
           statement = paste(
       ################ insert SQL here ######################
        "SELECT m.stateid AS state_code,\
        	m.cntyid AS county_code,\
        	m.siteid AS site_id,\
        	m.parm_code AS parameter,\
        	m.poc_code AS poc,\
        	o.dur_code AS sample_duration,\
		o.unitid AS unit,\
        	o.method_code AS method,\
        	o.sampldate AS date,\
        	o.startime AS start_time,\
        	o.value AS sample_value,\
        	o.nulldata AS nulldatacode,\
                NULL AS sampling_frequency,\
		NULL AS monitor_protocol_id,\
        	o.qual_code\
           FROM aqs.monitor m \
           JOIN aqs.obs_value o \
             ON m.id_mon = o.id_mon \ 
          WHERE m.stateid = '27' \
            AND m.parm_code = '44201' \
            AND o.sampldate BETWEEN '2014-06-01' AND '2014-06-07'\
	"
       ########################################################
        		     )); 


#***********************************************************************************************

## Closes the connection
dbDisconnect(con)

## Frees all the resources on the driver
dbUnloadDriver(drv)

```
</div>



### Air toxics Data Explorer{#toxics}

View and download summarized air toxics monitoring data results from the online [Air Toxics Data Explorer](https://www.pca.state.mn.us/air/air-toxics-data-explorer).

### Criteria Pollutant Data Explorer{#criteria}

View and download MPCA calculated annual criteria pollutant design values from the online [Criteria Pollutant Data Explorer] (https://www.pca.state.mn.us/air/criteria-pollutant-data-explorer).

### Air Quality Index Summary Reports{#AQI}

View and download annual AQI Summary Reports (based on final montiroing data) from the online [Air Quality Index Data Explorer](https://www.pca.state.mn.us/air/annual-aqi-summary-reports).

### Air Monitoring for PAHs{#PAHs}

View and download PAH monitoring results from the community and facility based special projects online at [Air Monitoring for PAHs](https://www.pca.state.mn.us/air/pah-study-results).

### Internal Data Explorers {#tableau}

Not all data analysis projects are ready or intended for external audiences. You can find a variety of analzyed monitoring results on the internal Tableau Server. 

- [Air Data Analysis](http://tableau.pca.state.mn.us/#/projects/113/workbooks) 
- [Air Modeling and Risk Evaluation](http://tableau.pca.state.mn.us/#/projects/72/workbooks)

## Health and standards

### Inhalation health benchmarks (IHBs) {#IHBs}

The inhalation health benchmarks used by MPCA are available on the web in these formats:

- __PDF:__ https://www.pca.state.mn.us/sites/default/files/aq9-28.pdf 
- __Excel:__ https://www.pca.state.mn.us/sites/default/files/aq9-22.xlsm
- __CSV:__ https://raw.githubusercontent.com/MPCA-air/health-values/master/Inhalation_Health_Benchmarks(IHBs).csv


<br>

Use the following R code to fetch the most recent inhalation health benchmarks and references used by MPCA.


<div class="toggle">
<button class = "btn_code">Show __R__ code</button>


```{r, warnings = FALSE}
library(readr)

url  <- "https://raw.githubusercontent.com/MPCA-air/health-values/master/Inhalation_Health_Benchmarks(IHBs).csv"

ihbs <- read_csv(url) 
```
</div>


<br>


### Air Quality Standards (NAAQS and MAAQS) {#NAAQS}
Criteria air pollutants including: particulate (TSP, PM10, PM2.5), ozone, lead, sulfur dioxide, nitrogen dioxide, and carbon monoxide are regulated via ambient air quality standards. Ambient air quality standards are set at the national (NAAQS) and state (MAAQS) level. 


__NAAQS__

The Clean Air Act, which was last amended in 1990, requires EPA to set National Ambient Air Quality Standards (40 CFR part 50) for pollutants considered harmful to public health and the environment. The Clean Air Act identifies two types of national ambient air quality standards. Primary standards provide public health protection, including protecting the health of "sensitive" populations such as asthmatics, children, and the elderly. Secondary standards provide public welfare protection, including protection against decreased visibility and damage to animals, crops, vegetation, and buildings.

- A summary of current NAAQS is available on EPA's website:
    - https://www.epa.gov/criteria-air-pollutants/naaqs-table
- When calculating NAAQS design values, analysts must follow the procedures defined in the pollutant specific [appendices to 40 CFR 50](https://www.ecfr.gov/cgi-bin/text-idx?SID=c118ce8b63f65737a282c4281a59abf0&mc=true&node=pt40.2.50&rgn=div5).
- In August each year, EPA posts official design values here: 
   - https://www.epa.gov/air-trends/air-quality-design-values

<br>


__MAAQS__

Minnesota Ambient Air Quality Standards (MAAQS) are established in [Minnesota Administrative Rules 7009](https://www.revisor.mn.gov/rules?id=7009&keyword_type=all&keyword=7009&keyword_sg=rule&redirect=0).

In most cases, the MAAQS are the same as the NAAQS. The MAAQS also include standards for two pollutants that are not covered by the NAAQS: TSP and hydrogen sulfide. The MAAQS were last updated in January 2017.

When calculating MAAQS design values:

- If MAAQS = NAAQS, use methods described in appendices to 40 CFR 50.
- If MAAQS = revoked NAAQS, use methods described in archived appendices to 40 CFR 50.
- For MAAQS without a NAAQS, such as H2S, use the "Form of the standard" language to guide your calculations.  



## Air modeling

### NATA modeling {#nata}
The National Air Toxics Assessment is a nationwide air modeling effort to provide air concentrations and risks for all U.S. census tracts. These results may be pulled from a map project or data tables at [NATA](https://www.epa.gov/national-air-toxics-assessment). After each inventory is completed the Minnesota statewide cumulative air pollution model is compared to these results.

<br>


### MNRISKS statewide risk modeling {#mnrisks}
MNRISKS is the statewide cumulative air pollution model that is produced by MPCA every three years with the air toxics emissions inventory publication. The model itself produces point estimates for air concentrations and potential human health risks for hundreds of air pollutants across Minnesota. The model also incorporates a date and transport component that produces multi-pathway risk results. Census block group averaged results are available on MPCA's [Air modeling and human health](https://www.pca.state.mn.us/air/air-modeling-and-human-health) webpage.
<br>


### Downscaler modeling results for Ozone and PM2.5 {#downscale}
Downscaled data _(a blend of modeling and monitoring results)_ are provided by the CDC in cooperation with the EPA for the pollutants ozone and PM-2.5. Daily predicitons are available for each Census tract throughout the country for the years 2001 to 2013.

- CDC information about this platform is available online at [https://ephtracking.cdc.gov/showAirData.action](https://ephtracking.cdc.gov/showAirData.action).
- Data from this platform can be downloaded from the EPA at [https://www.epa.gov/air-research/downscaler-model-predicting-daily-air-pollution](https://www.epa.gov/air-research/downscaler-model-predicting-daily-air-pollution).
- Downloaded data filtered to Minnesota results is available internally in the folder: `X:\Programs\Air_Quality_Programs\Air Monitoring Data and Risks\6 Air Data\EPA Downscaler Modeling`.


### CMAQ Ozone modeling {#cmaq}
The Community Multiscale Air Quality Modeling System (CMAQ) is defined by EPA as:

> an active open-source project of the EPA that consists of a suite of programs for conducting air quality model simulations. CMAQ combines current knowledge in atmospheric science and air quality modeling, and an open-source framework to deliver fast, technically sound estimates of ozone, particulates, air toxics and acids deposition.

The information and data from this platform can be found at the following website [CMAQ](https://www.epa.gov/cmaq).



## Context


### MN Emissions Inventory {#mn-ei}
Every year all facilities (stationary point sources) report criteria pollutant emissions and every three years facilities report air toxics emissions. The EPA and the state of Minnesota emissions inventory team also calculate and report emissions for all other types of emissions sources such as mobile, non-road mobile, and area sources. These non-point emissions are reported every three years with the air toxics emissions. The Minnesota emission inventory is the foundation of MNRISKS. These emissions levels are reported in several data tools on the MPCA website. Their data and the visualization tools can be found on the following website [https://www.pca.state.mn.us/air/emissions-data](https://www.pca.state.mn.us/air/emissions-data).

<br>


### EPA's NEI {#nei}
The National Emissions Inventory (NEI) provides air toxics and criteria and air toxic pollutant emissions for the entire U.S. on the same schedule as described in the Minnesota Emissions Inventory section. This information can be found at the following website [https://www.epa.gov/air-emissions-inventories/national-emissions-inventory-nei](https://www.epa.gov/air-emissions-inventories/national-emissions-inventory-nei).


### Facility locations {#fac-coords}
The most recent compilation of facility coordinates was performed for the 2017 emission inventory. This data is available in the `INV_SOURCES` table found in the _RAPIDS_ schema of MPCA's _DELTA_ database.


Use the following code to load the current facility coordinates.

<div class="toggle">
<button class="btn_code">Show __R__ code</button>

```{r, eval = T}
# This script connects to the MPCA database DELTA. 
# A dplyr query collects source coordinates from the RAPIDS schema.
                                                                          
# Load packages
library(dplyr)
library(RODBC)
library(readr)

```

You can view available database connections in R using the function `odbcDataSources()`.
```{r}

odbcDataSources()

```

<br>


To connect to `deltaw`, use the function `odbcConnect()`.

```{r, warning = F}

# Load credentials
credentials <- read_csv("X:/Agency_Files/Outcomes/Risk_Eval_Air_Mod/_Air_Risk_Evaluation/R/R_Camp/Student Folder/credentials.csv")

user      <- credentials$delta_user
password  <- credentials$delta_pwd

# Alternatively, use your own
#user      <- "ta*******"
#password  <- "da**_*******"
  
# Connect to DELTA
deltaw <- odbcConnect("deltaw", 
                      uid = user, 
                      pwd = password,
                      believeNRows = FALSE)


# Show all tables in RAPIDS schema
rapids_tbls <- sqlTables(deltaw, tableType = "TABLE", schema = "RAPIDS")  

head(rapids_tbls)

# Get inventory year codes
inv_codes  <- sqlQuery(deltaw, "SELECT * FROM RAPIDS.INV_INVENTORIES", max = 100, stringsAsFactors = F)

# Get code for 2017
inv_id  <- filter(inv_codes, INVENTORY_YEAR == 2017)$RID

# Get sources for inventory year
sources   <- sqlQuery(deltaw, paste0("SELECT * FROM RAPIDS.INV_SOURCES WHERE INVENTORY_RID = ", inv_id),
                        max              = 10000, 
                        stringsAsFactors = F, 
                        as.is            = T)


# Get source coordinates
src_coords   <- sqlQuery(deltaw, "SELECT * FROM RAPIDS.INV_COORDINATES",
                        max              = 100000, 
                        stringsAsFactors = F, 
                        as.is            = T)


# Join coordinates to sources
sources <- left_join(sources, src_coords, by = c("RID" = "ENTITY_RID"))


# View data 
sources %>% select(SOURCE_ID, SOURCE_TYPE, SOURCE_NAME, LONGITUDE, LATITUDE) %>% glimpse()

```
</div>


### Weather observations {#wx-obs}
Historical meteorological observations are available from multiple sources. 

__Raw data__

1. An internal Tableau workbook provides raw results for Minnesota meteorological stations: [tableau.pca.state.mn.us/#/workbooks/5714](tableau.pca.state.mn.us/#/workbooks/5714).


__Quality assured data__

1. The AQI forecast uses a web API provided by [_DarkSky_](https://darksky.net/dev) for current forecast information and quality assured historical observations.


### HYSPLIT wind trajectories {#hysplit}
Wind trajectories are useful for determining the primary sources contributing to elevated air monitoring results. Trajectory results for the air monitoring netowork are available in WAIR for the years 2007 to 2017. The R package [SplitR](https://github.com/rich-iannone/SplitR) was used to automate HYSPLIT modeling for each air monitoring location.

Use the following code to query WAIR for HYSPLIT results.

<div class="toggle">
<button class="btn_code">Show __R__ code</button>
```{r, eval = F}
# This script connects to the MPCA database WAIR.  
# A dplyr query collects HYSPLIT modeling results for Anoka Airport.
                                                                                

# Load packages
library(dplyr)

# Open a connection to the database WAIR, schema hys ##
my_wair <- src_postgres(dbname = 'wair', host = "eiger", user = "username", password = "password")

# Show tables
src_tbls(my_wair) %>% sort()


# Connect to hys.backtrajectory table ##
hys <- tbl(my_wair, "hys.backtrajectory")

hys <- tbl(my_wair, sql('hys.backtrajectory'))

# Collect data for Anoka Airport after year 2010 ##
hys_mpls  <- hys %>% 
               select(-the_geom) %>%
               filter(site_catid == "27-003-1002", yr > 10) %>% 
               collect(n = 2000)

# View data 
head(hys_mpls)

```
</div>


    
### Land use maps {#landuse}
Land use shapefiles are maintained by MPCA GIS technical staff and stored on the agency R-drive at `R:\landuse_landcover`.



### United States Census boundaries {#census}
Census boundaries can be loaded into R for mapping air data to Census tracts and block groups.


Use the following code to download and map MN boundaries.

<div class="toggle">
<button class="btn_code">Show __R__ code</button>
```{r tigris-1, results="hide"}
# This script downloads shapefiles of Minnesota 
## Counties
## Census tracts
## Census Block groups  

# Load packages
library(tigris)

# Load boundaries
county_bounds <- counties(state = "MN", cb = T)
```

```{r county-plot}
# Plot 
plot(county_bounds, col = "steelblue")
```


__Tracts & Block groups__
```{r, eval=F}
tract_bounds  <- tracts(state = "MN", cb = T)

bg_bounds     <- block_groups(state = "MN", cb = T)

```
</div>


### American Community Survey (ACS) {#acs}
The ACS provides updated demographic statistics used for population estimates and Environmental Justice indicators.  

Use the following code to download Minnesota ACS results.

<div class="toggle">
<button class="btn_code">Show __R__ code</button>
```{r, eval = F}
# This script downloads American Community Survey (ACS) results for MN

# Load packages
library(tidycensus)

# ACS data requires a Census key
# Visit: http://api.census.gov/data/key_signup.html
census_api_key("Your_API_key")

# View all ACS variables
acs_variables <- load_variables(2015, "acs5", cache = TRUE)


# Download 5-yr population estimates for 2015
pops_2015 <- get_acs(geography = "tract", 
                     state     = "MN", 
                     variables = "B01003_001", 
                     survey    = "acs5", 
                     year      = 2015)


# Download decennial population estimates for 2010
pops_2010 <- get_decennial(geography = "tract", 
                           state     = "MN", 
                           variables = "P0080001", 
                           year      = 2010)


# Download household median income for 2015
med_inc_2015 <- get_acs(geography = "tract", 
                        state     = "MN", 
                        variables = "B19013_001", 
                        survey    = "acs5", 
                        year      = 2015)

```
</div>



<br> [Back to top](#get-data)

