[
["data-validation-kristie.html", " Data validation (Kristie) 2.1 Identifying Instrument drift or leaks in a system. 2.2 Identify exceptional and extreme values aka outliers. 2.2 Identify sequential repeats aka “sticky” numbers", " Data validation (Kristie) Environmental monitoring data can be subject to error. Three important errors to look for are: 2.1 Leaks and sample contamination ?? Instrument errors such as drift or repeated results (sticking values) 2.2 Outliers or extreme values Validation steps Identify exceptional values. Identify sequential identical values (sticking). Identify potential instrument drift. Report findings to laboratory for further investigation. Why not average the exceptional data over the year and assume the problem will go away? Further investigation by laboratory staff is required if the laboratory equipment or system is in error. If the laboratory is not in error, these concentrations require additional investigation by data analysts and potentially by air pollution source specialists. For these reasons, these data validation steps are critical. A decreasing signal or repeated sequential measurement means that the data are not interpretable. An exceptionally high value could mean laboratory contamination or potentially could contribute to human health impacts if the high value is accurate. Notes Possible Contamination Issues-by site and pollutant 3*IQR: I used as a simple outlier identifier in EU guidelines. This includes a lot of data for UFPs. Cassie has tried: 3*75th percentile(UFP) - quantiles from previous year of data 2.5 *75th percentile of the data (put in Derek’s explanation) this is for integrated air toxics data 3*SD (Poor performance) Site mean more than twice the second highest site mean(NO) Sites with maxima over 2X the next highest value(NO) Only one detection at a site (special case) And Detection was greater than 3X the MDL And Detection was within 10% of state maximum that year Possible Sample loss issues (leaks) by site and pollutant Check for several (2,3) below MDL values when values have been above MDLs previously (need discussion). MDL would be from the previous year. I tried taking the mean of 5 sequential values, and then the next 5 sequential values. If the second set of means was 1.5 times less than the first mean I flagged the values. Recommendation: Use the [75th percentile * 3] for all pollutants. Sample R script Click the button below to view a step by step example of the methods above. Show R code Goals: Find extreme values that may be in error or from contamination. Find 3 repeating values that are exactly the same. Find low values where this is not common. Do this in a routine way (identify frequency of validation checks). The following sections on data validation will use the example monitoring data loaded below. library(tidyverse) library(stringr) library(RcppRoll) library(lubridate) library(car) ##need to confirm that this data set has sequential repeats, some high values and at least 10 dates with numbers data &lt;- read_csv(&#39;https://raw.githubusercontent.com/MPCA-air/air-methods/master/airtoxics_data_2009_2013.csv&#39;) colnames(data) &lt;- c(&quot;aqs_id&quot;, &quot;poc&quot;, &quot;param_code&quot;, &quot;date&quot;, &quot;conc&quot;, &quot;null_code&quot;, &quot;md_limit&quot;, &quot;pollutant&quot;, &quot;year&quot;, &quot;cas&quot;) dt_options &lt;- list(scrollX = T, autoWidth = T, searching = F, ordering=F, lengthChange = F, paginate=F, info=F) Table: Sample monitoring data 2.1 Identifying Instrument drift or leaks in a system. The test looks for a difference in variance of carbon tetrachloride between a calendar quarter for two consecutive years. Carbon tetrachloride was chosen because it is a banned substance and no longer in use, it has very few below detection limit values, and no direct sources. It has seasonally variable concentrations, so calendar quarters were compared to eliminate the detection of seasonal differences. The statistical test used was a Levenes Test for homogeneity of variance. Sample R script Click the button below to view a step by step example of the method above. Show R code data$conc &lt;- as.numeric(data$conc) data$aqs_id &lt;- as.character(data$aqs_id) sites &lt;- unique(data$aqs_id) years &lt;- unique(data$year) data$quarter = quarter(data$date) quarters &lt;- unique(data$quarter) pocs &lt;- unique(data$poc) clean_values = function(data) { data$conc = as.numeric(as.character(data$conc)) data$conc[abs(data$conc) &gt;= 999] = NA return(data) } data = clean_values(data) levene_function = function(conc, quarter_year, row, col) { if(length(unique(quarter_year))&lt;2){ return(NA)} data = data.frame(conc = conc, quarter_year = quarter_year) return(leveneTest(conc~as.factor(quarter_year), data = data)[row,col]) } leak_table_unfiltered &lt;- data.frame() for(i in max(years):max(years)-1:length(years)){ for(j in i+1){ data_carbontet=data.frame() data_carbontet &lt;- filter(data, pollutant==&quot;Carbon Tetrachloride&quot;, !is.na(conc), year %in% c(i, j)) data_carbontet$quarter_year = paste(data_carbontet$quarter, &quot;_&quot;, data_carbontet$year) data_carbontet &lt;- data_carbontet %&gt;% group_by(aqs_id, poc, quarter) %&gt;% summarise(fvalue_levene = levene_function(conc, quarter_year, 1,2), pval_levene = levene_function(conc, quarter_year, 1,3), deg_free_levene = levene_function(conc, quarter_year, 2,1), Year_1 = min(year), Year_2 = max(year), Mean_Year_1 = mean(conc[year==min(year)], na.rm=T), Mean_Year_2 = mean(conc[year==max(year)], na.rm=T)) %&gt;% ungroup() leak_table_unfiltered &lt;- rbind(leak_table_unfiltered,data_carbontet) } } leak_table &lt;- filter(leak_table_unfiltered, pval_levene&lt;0.01, abs(Year_1-Year_2)==1) leak_table$Warning_Type &lt;- &quot;Decrease_in_Measurements&quot; datatable(head(leak_table, 10), options = dt_options) %&gt;% formatSignif(c(&quot;fvalue_levene&quot;, &quot;pval_levene&quot;, &quot;Mean_Year_1&quot;, &quot;Mean_Year_2&quot;), digits = 2) 2.2 Identify exceptional and extreme values aka outliers. These are detected by comparing each measured concentration to 3 X the 75th percentile of the data set by year, site, and pollutant. For now, pocs collocated measurements are not tested separately. Sample R script Click the button below to view a step by step example of the method above. Show R code # Test for exceptionally high values [above 75th percentile X 3] high_data &lt;- group_by(data, year, aqs_id, pollutant) %&gt;% mutate(AR_Mean = mean(conc, na.rm=T), Percentile_75 = quantile(conc, 0.75, na.rm=T), Percentile_75_X3 = Percentile_75*3) %&gt;% ungroup() high_data &lt;- filter(high_data, conc&gt;Percentile_75_X3, !is.na(conc), AR_Mean&gt;md_limit, Percentile_75&gt;0) high_data$Warning_Type &lt;- &quot;Exceptionally_High_Value_Test&quot; high_data &lt;- unique(high_data) datatable(head(high_data, 10), options = dt_options) high_data &lt;- high_data[, c(&quot;date&quot;, &quot;pollutant&quot;, &quot;aqs_id&quot;, &quot;Warning_Type&quot;)] ##Toxics - Multiplying by 3 returns ~4000/1176818 values as extreme, multiplying by 1.5 returns &gt;20,000. Multiplying by 3 returns between 2 and 45% of analyte/site/year groups. ##UFP - Multiplying by 3 returns 28894 of 1335083 total values. Multiplying by 3 returns between 2 and 15% of analyte/site/year groups. ##PAHs - Multiplying by 3 returns 168 of 39298 total values. Multiplying by 3 returns between 3 and 10% of analyte/site/year groups. 2.2 Identify sequential repeats aka “sticky” numbers Three sequential replicate values may be a result of a machine error. # Test for exceptionally high values [above 75th percentile X 3] repeat_data &lt;- group_by(data, poc, year, aqs_id, pollutant) %&gt;% arrange(year, aqs_id, poc, pollutant, date) %&gt;% mutate(Previous_Day = lag(conc, 1), Two_Days_Prior = lag(conc, 2)) %&gt;% ungroup() repeat_data &lt;- mutate(repeat_data, Repeat_Test = ifelse(round(conc, digits=4)==round(Previous_Day, digits=4) &amp; round(Previous_Day, digits=4)==round(Two_Days_Prior, digits=4), &quot;TRUE&quot;, &quot;FALSE&quot;)) repeat_data$Warning_Type &lt;- &quot;Repeat_Test&quot; repeat_data &lt;- filter(repeat_data, conc&gt;0 &amp; Repeat_Test==TRUE) datatable(head(repeat_data, 10), options = dt_options) repeat_data &lt;- repeat_data[, c(&quot;date&quot;, &quot;pollutant&quot;, &quot;aqs_id&quot;, &quot;Warning_Type&quot;)] ###There are many repeating values in the Toxics data. None in PAHs. Approximately 3200 for UFPs, but this is 15 minute data. We may need a more stringent test for UFPs. Table: Dates and pollutants to check including the potential issue Contributors Kristie Ellickson, Cassie McMahon, Dorian Kvale, Derek Nagel References USEPA Technical Support Document for the Nation Air Toxics Trends Sites European Union Guide toe Data Validation [US EPA Guidance on Data Verification and Data Validation] (https://www.epa.gov/sites/production/files/2015-06/documents/g8-final.pdf) [US EPA Data Validation Workbook Presentation and Training Materials] (https://www3.epa.gov/ttnamti1/files/ambient/airtox/workbook/T-Workbook_Secs1-8.pdf) [US EPA Data Validation Workbook] (https://nepis.epa.gov/Exe/ZyNET.exe/P1006PAB.TXT?ZyActionD=ZyDocument&amp;Client=EPA&amp;Index=2006+Thru+2010&amp;Docs=&amp;Query=&amp;Time=&amp;EndTime=&amp;SearchMethod=1&amp;TocRestrict=n&amp;Toc=&amp;TocEntry=&amp;QField=&amp;QFieldYear=&amp;QFieldMonth=&amp;QFieldDay=&amp;IntQFieldOp=0&amp;ExtQFieldOp=0&amp;XmlQuery=&amp;File=D%3A%5Czyfiles%5CIndex%20Data%5C06thru10%5CTxt%5C00000016%5CP1006PAB.txt&amp;User=ANONYMOUS&amp;Password=anonymous&amp;SortMethod=h%7C-&amp;MaximumDocuments=1&amp;FuzzyDegree=0&amp;ImageQuality=r75g8/r75g8/x150y150g16/i425&amp;Display=hpfr&amp;DefSeekPage=x&amp;SearchBack=ZyActionL&amp;Back=ZyActionS&amp;BackDesc=Results%20page&amp;MaximumPages=1&amp;ZyEntry=1&amp;SeekPage=x&amp;ZyPURL) [Review article by Helsel, D about non-detects and substitution methods.] (https://academic.oup.com/annweh/article/54/3/257/223531/Much-Ado-About-Next-to-Nothing-Incorporating) [A Chemosphere review article describing why BDL substitution should not be done.] (https://pdfs.semanticscholar.org/182e/9278fc36dd73d48a414b8fbc30a44ea314d3.pdf) [Temporal variability of selected air toxics in the United States] (http://www.sciencedirect.com/science/article/pii/S1352231007004840) [Spatial and temporal analysis of national air toxics data] (http://www.tandfonline.com/doi/pdf/10.1080/10473289.2006.10464576) "]
]
